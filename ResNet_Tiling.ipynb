{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import gc\n",
    "import random\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import skimage.io\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "import scipy as sp\n",
    "\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "import torchvision.models as models\n",
    "import torch.cuda\n",
    "\n",
    "from albumentations import Compose, Transpose, Normalize, HorizontalFlip, VerticalFlip\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "epochs = 1 if DEBUG else 20\n",
    "df_train = df_train.sample(100).reset_index(drop=True) if DEBUG else df_train\n",
    "height=256\n",
    "width=256\n",
    "lr=1e-4\n",
    "batch_size=2\n",
    "fold=0\n",
    "image_size=256\n",
    "tile_size=256\n",
    "#epochs=20\n",
    "seed=42\n",
    "n_tiles=12\n",
    "num_workers=4\n",
    "warmup_factor=10\n",
    "target_size=6 #1\n",
    "target_col='isup_grade'\n",
    "n_fold=4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "    \n",
    "def init_logger(log_file='train.log'):\n",
    "    from logging import getLogger, DEBUG, FileHandler,  Formatter,  StreamHandler\n",
    "    \n",
    "    log_format = '%(asctime)s %(levelname)s %(message)s'\n",
    "    \n",
    "    stream_handler = StreamHandler()\n",
    "    stream_handler.setLevel(DEBUG)\n",
    "    stream_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    file_handler = FileHandler(log_file)\n",
    "    file_handler.setFormatter(Formatter(log_format))\n",
    "    \n",
    "    logger = getLogger('PANDA')\n",
    "    logger.setLevel(DEBUG)\n",
    "    logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "    \n",
    "    return logger\n",
    "\n",
    "LOG_FILE = 'train.log'\n",
    "LOGGER = init_logger(LOG_FILE)\n",
    "\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tiles(img):\n",
    "        tiles = []\n",
    "        H, W, C = img.shape\n",
    "        #1\n",
    "        pad_H = (tile_size - H % tile_size) % tile_size \n",
    "        pad_W = (tile_size - W % tile_size) % tile_size \n",
    "        #2\n",
    "        img2 = np.pad(img,[[pad_H // 2, pad_H - pad_H // 2], [pad_W // 2,pad_W - pad_W//2], \n",
    "                            [0,0]], constant_values=255)\n",
    "        \n",
    "        #3\n",
    "        img3 = img2.reshape(\n",
    "            img2.shape[0] // tile_size,\n",
    "            tile_size,\n",
    "            img2.shape[1] // tile_size,\n",
    "            tile_size,\n",
    "            3)\n",
    "        #4\n",
    "        img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n",
    "        n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n",
    "        #5\n",
    "        if len(img3) < n_tiles:\n",
    "            img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n",
    "        #6\n",
    "        idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n",
    "        img3 = img3[idxs]\n",
    "        for i in range(len(img3)):\n",
    "            tiles.append({'img':img3[i], 'idx':i})\n",
    "        return tiles, n_tiles_with_info >= n_tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 image_size,\n",
    "                 n_tiles=n_tiles,\n",
    "                 rand=False,\n",
    "                 transform=None,\n",
    "                ):\n",
    "\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_size = image_size\n",
    "        self.n_tiles = n_tiles\n",
    "        self.rand = rand\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        img_id = row.image_id\n",
    "        \n",
    "        tiff_file = os.path.join('train_images', f'{img_id}.tiff')\n",
    "        image = skimage.io.MultiImage(tiff_file)[1]\n",
    "        tiles, OK = get_tiles(image)\n",
    "\n",
    "        if self.rand:\n",
    "            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n",
    "        else:\n",
    "            idxes = list(range(self.n_tiles))\n",
    "\n",
    "        n_row_tiles = int(np.sqrt(self.n_tiles))\n",
    "        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n",
    "        for h in range(n_row_tiles):\n",
    "            for w in range(n_row_tiles):\n",
    "                i = h * n_row_tiles + w\n",
    "    \n",
    "                if len(tiles) > idxes[i]:\n",
    "                    this_img = tiles[idxes[i]]['img']\n",
    "                else:\n",
    "                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n",
    "                this_img = 255 - this_img\n",
    "                if self.transform is not None:\n",
    "                    this_img = self.transform(image=this_img)['image']\n",
    "                h1 = h * image_size\n",
    "                w1 = w * image_size\n",
    "                images[h1:h1+image_size, w1:w1+image_size] = this_img\n",
    "\n",
    "        if self.transform is not None:\n",
    "            images = self.transform(image=images)['image']\n",
    "        images = images.astype(np.float32)\n",
    "        images /= 255\n",
    "        images = images.transpose(2, 0, 1)\n",
    "\n",
    "        label = np.zeros(5).astype(np.float32)\n",
    "        label[:row.isup_grade] = 1.\n",
    "        return torch.tensor(images), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(*, data):\n",
    "    \n",
    "    assert data in ('train', 'valid')\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),])\n",
    "    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>isup_grade</th>\n",
       "      <th>gleason_score</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>777e89beb78fc98db5806423fe7f7254</td>\n",
       "      <td>radboud</td>\n",
       "      <td>5</td>\n",
       "      <td>5+4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b1fbe9701b14bf285318abcbf002d5ea</td>\n",
       "      <td>radboud</td>\n",
       "      <td>4</td>\n",
       "      <td>4+4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441b527337da4319cf700b6e7da9fa0c</td>\n",
       "      <td>radboud</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9d931784c507a8633fdc623cc916d8d3</td>\n",
       "      <td>karolinska</td>\n",
       "      <td>0</td>\n",
       "      <td>0+0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d13eecf391803d164d6f0fd89f1871e8</td>\n",
       "      <td>radboud</td>\n",
       "      <td>1</td>\n",
       "      <td>3+3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image_id data_provider  isup_grade gleason_score  \\\n",
       "0  777e89beb78fc98db5806423fe7f7254       radboud           5           5+4   \n",
       "1  b1fbe9701b14bf285318abcbf002d5ea       radboud           4           4+4   \n",
       "2  441b527337da4319cf700b6e7da9fa0c       radboud           1           3+3   \n",
       "3  9d931784c507a8633fdc623cc916d8d3    karolinska           0           0+0   \n",
       "4  d13eecf391803d164d6f0fd89f1871e8       radboud           1           3+3   \n",
       "\n",
       "   fold  \n",
       "0     0  \n",
       "1     3  \n",
       "2     2  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(4, shuffle=True, random_state=42)\n",
    "df_train['fold'] = -1\n",
    "for i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['isup_grade'])):\n",
    "    df_train.loc[valid_idx, 'fold'] = i\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_setup():\n",
    "    \n",
    "    train_idx = np.where((df_train['fold'] != fold))[0]\n",
    "    valid_idx = np.where((df_train['fold'] == fold))[0]\n",
    "\n",
    "    global dataset_train, dataset_valid, train_loader, valid_loader, df_valid, df_this\n",
    "\n",
    "    df_this  = df_train.loc[train_idx]\n",
    "    df_valid = df_train.loc[valid_idx]\n",
    "\n",
    "    dataset_train = Dataset(df_this , image_size, n_tiles, transform=get_transforms(data='train'))\n",
    "    dataset_valid = Dataset(df_valid, image_size, n_tiles, transform=get_transforms(data='valid'))\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n",
    "\n",
    "    return \n",
    "\n",
    "def build_the_network():\n",
    "    \n",
    "    global model\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "                      nn.Linear(num_ftrs, 5))\n",
    "    model = model.to(device) \n",
    "    \n",
    "    return \n",
    "\n",
    "def optim():\n",
    "    \n",
    "    global optimizer, scheduler, criterion\n",
    "    optimizer = Adam(model.parameters(), lr=lr/warmup_factor, amsgrad=False)\n",
    "#scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True, eps=1e-6)\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs-1)\n",
    "    scheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, \n",
    "                                   total_epoch=1, \n",
    "                                   after_scheduler=scheduler_cosine)\n",
    "    criterion = nn.BCEWithLogitsLoss() \n",
    "    \n",
    "    return \n",
    "\n",
    "def train_epoch(loader, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader)\n",
    "    for (data, target) in bar:\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        loss_func = criterion\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(data)\n",
    "        loss = loss_func(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_np)\n",
    "        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n",
    "        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def val_epoch(loader, get_output=False):\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    LOGITS = []\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (data, target) in tqdm(loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            logits = model(data)\n",
    "            loss = criterion(logits, target)\n",
    "\n",
    "            pred = logits.sigmoid().sum(1).detach().round()\n",
    "            LOGITS.append(logits)\n",
    "            PREDS.append(pred)\n",
    "            TARGETS.append(target.sum(1))\n",
    "\n",
    "            val_loss.append(loss.detach().cpu().numpy())\n",
    "        val_loss = np.mean(val_loss)\n",
    "\n",
    "    LOGITS = torch.cat(LOGITS).cpu().numpy()\n",
    "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()\n",
    "    acc = (PREDS == TARGETS).mean() * 100.\n",
    "    \n",
    "    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n",
    "    qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n",
    "    qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n",
    "    print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n",
    "\n",
    "    if get_output:\n",
    "        return PREDS\n",
    "    else:\n",
    "        return PREDS,TARGETS,LOGITS, val_loss, acc, qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/38 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep 12 15:47:32 2020 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.77850, smth: 0.66233: 100%|██████████| 38/38 [00:18<00:00,  2.04it/s]\n",
      "100%|██████████| 13/13 [00:03<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwk 0.0 qwk_k 0.0 qwk_r 0.0\n",
      "Sat Sep 12 15:47:55 2020 Epoch 1, lr: 0.0000100, train loss: 0.66233, val loss: 0.62946, acc: 4.00000, qwk: 0.00000\n"
     ]
    }
   ],
   "source": [
    "data_setup()\n",
    "build_the_network()\n",
    "optim()\n",
    "\n",
    "qwk_max = 0.\n",
    "best_file = 'best_resnet50_tiled.pth'\n",
    "for epoch in range(1, epochs+1):\n",
    "    print(time.ctime(), 'Epoch:', epoch)\n",
    "    scheduler.step(epoch-1)\n",
    "\n",
    "    train_loss = train_epoch(train_loader, optimizer)\n",
    "    PREDS, TARGETS, LOGITS, val_loss, acc, qwk = val_epoch(valid_loader)\n",
    "\n",
    "    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, acc: {(acc):.5f}, qwk: {(qwk):.5f}'\n",
    "    print(content)\n",
    "\n",
    "    if qwk > qwk_max:\n",
    "        print('score progress: ({:.6f} --> {:.6f}).  Saving model ...'.format(qwk_max, qwk))\n",
    "        torch.save(model.state_dict(), best_file)\n",
    "        qwk_max = qwk \n",
    "\n",
    "torch.save(model.state_dict(), os.path.join('final_resnet50_tiled.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2.]\n",
      "[5. 0. 1. 5. 1. 2. 0. 1. 3. 4. 1. 1. 0. 1. 0. 1. 0. 5. 1. 5. 3. 0. 4. 5.\n",
      " 0.]\n",
      "[[ 0.25989306 -1.063205   -0.99710244 -1.4471527  -0.7404163 ]\n",
      " [ 0.2596209  -1.0972604  -0.98380655 -1.4158733  -0.75114566]\n",
      " [ 0.25071204 -1.0730724  -0.9860933  -1.4308074  -0.7395149 ]\n",
      " [ 0.26247847 -1.0713757  -1.0024192  -1.4485155  -0.74612516]\n",
      " [ 0.26025403 -1.0894552  -0.9963755  -1.4262763  -0.76121145]\n",
      " [ 0.2514897  -1.0979496  -1.0060452  -1.4589238  -0.76208246]\n",
      " [ 0.2589507  -1.1040052  -1.0133222  -1.4609251  -0.7720044 ]\n",
      " [ 0.24373199 -1.1047088  -0.9778441  -1.4185582  -0.746756  ]\n",
      " [ 0.265221   -1.1161801  -1.0056255  -1.4410576  -0.7686835 ]\n",
      " [ 0.25395536 -1.0690111  -1.0166548  -1.4520988  -0.7558238 ]\n",
      " [ 0.25793177 -1.1046823  -0.99891144 -1.4469073  -0.76737475]\n",
      " [ 0.2600941  -1.0853918  -1.013014   -1.4671478  -0.7727766 ]\n",
      " [ 0.25302732 -1.0917164  -1.0035732  -1.4555908  -0.7576212 ]\n",
      " [ 0.2605924  -1.1017995  -1.0279281  -1.4756144  -0.78260165]\n",
      " [ 0.25818044 -1.0948309  -0.9939347  -1.4261808  -0.7542043 ]\n",
      " [ 0.25282717 -1.0810041  -0.9891566  -1.4413898  -0.7536149 ]\n",
      " [ 0.25989377 -1.0982666  -0.9881082  -1.4223825  -0.7601218 ]\n",
      " [ 0.25755036 -1.0722727  -0.99156183 -1.4379561  -0.74030286]\n",
      " [ 0.25673032 -1.1013188  -0.9874617  -1.4164712  -0.7536738 ]\n",
      " [ 0.24986453 -1.0979971  -0.99040484 -1.4340904  -0.7610312 ]\n",
      " [ 0.2600189  -1.0856313  -0.9875293  -1.453669   -0.7546421 ]\n",
      " [ 0.2574355  -1.0969242  -1.0051429  -1.4493865  -0.7674267 ]\n",
      " [ 0.25529236 -1.0546447  -0.98152465 -1.4288229  -0.72513044]\n",
      " [ 0.25386387 -1.082012   -1.0193615  -1.4614588  -0.7614169 ]\n",
      " [ 0.2609833  -1.095406   -1.0107071  -1.4497612  -0.7645503 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(PREDS)\n",
    "print(TARGETS)\n",
    "print(LOGITS)\n",
    "cohen_kappa_score(PREDS, TARGETS)\n",
    "#type(PREDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score([2.,2.,2.],[0.,4.,0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path = ['best_resnet50_tiled.pth'] + sys.path\n",
    "model_dict = {'resnet50': 'best_resnet50_tiled.pth'}\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.Linear(256, 5),                   \n",
    "                      nn.Softmax()\n",
    "model.load_state_dict(torch.load(model_dict['resnet50']))\n",
    "#model.to(device)\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "model_weights = [] \n",
    "conv_layers = [] \n",
    "model_children = list(model.children())\n",
    "model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter to keep count of the conv layers\n",
    "counter = 0 \n",
    "# append all the conv layers and their respective weights to the list\n",
    "for i in range(len(model_children)):\n",
    "    if type(model_children[i]) == nn.Conv2d:\n",
    "        counter += 1\n",
    "        model_weights.append(model_children[i].weight)\n",
    "        conv_layers.append(model_children[i])\n",
    "    elif type(model_children[i]) == nn.Sequential:\n",
    "        for j in range(len(model_children[i])):\n",
    "            for child in model_children[i][j].children():\n",
    "                if type(child) == nn.Conv2d:\n",
    "                    counter += 1\n",
    "                    model_weights.append(child.weight)\n",
    "                    conv_layers.append(child)\n",
    "print(f\"Total convolutional layers: {counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the conv layers and the respective weights\n",
    "for weight, conv in zip(model_weights, conv_layers):\n",
    "    # print(f\"WEIGHT: {weight} \\nSHAPE: {weight.shape}\")\n",
    "    print(f\"CONV: {conv} ====> SHAPE: {weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 17))\n",
    "for i, filter in enumerate(model_weights[0]):\n",
    "    plt.subplot(8, 8, i+1) # (8, 8) because in conv0 we have 7x7 filters and total of 64 (see printed shapes)\n",
    "    plt.imshow(filter[0, :, :].detach(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('filter0.png')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and visualize an image\n",
    "image = skimage.io.MultiImage(os.path.join(\"train_images\",\n",
    "                                           '08f055372c7b8a7e1df97c6586542ac8.tiff'))\n",
    "\n",
    "image = cv2.resize(image[-1], (height, width))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "# define the transforms\n",
    "transform = Compose([HorizontalFlip(p=0.5),\n",
    "        VerticalFlip(p=0.5),\n",
    "       Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],),\n",
    "           ToTensorV2()])\n",
    "image = np.array(image)\n",
    "# apply the transforms\n",
    "augmented = transform(image=image)\n",
    "print(type(augmented))\n",
    "image = augmented['image']\n",
    "print(image.size())\n",
    "# unsqueeze to add a batch dimension\n",
    "image = image.unsqueeze(0)\n",
    "print(image.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the image through all the layers\n",
    "results = [conv_layers[0](image)]\n",
    "for i in range(1, len(conv_layers)):\n",
    "    # pass the result from the last layer to the next layer\n",
    "    results.append(conv_layers[i](results[-1]))\n",
    "# make a copy of the `results`\n",
    "outputs = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize 64 features from each layer \n",
    "# (although there are more feature maps in the upper layers)\n",
    "for num_layer in range(len(outputs)):\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    layer_viz = outputs[num_layer][0, :, :, :]\n",
    "    layer_viz = layer_viz.data\n",
    "    print(layer_viz.size())\n",
    "    for i, filter in enumerate(layer_viz):\n",
    "        if i == 64: # we will visualize only 8x8 blocks from each layer\n",
    "            break\n",
    "        plt.subplot(8, 8, i + 1)\n",
    "        plt.imshow(filter, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    #print(f'Saving layer {num_layer} feature maps...')\n",
    "    plt.savefig(f'resnet50_tiled_feature_maps/outputs_layer_{num_layer}.png') \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
